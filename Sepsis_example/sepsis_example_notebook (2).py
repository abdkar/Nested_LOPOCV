{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sepsis Detection in ICU Patients: Subject-Aware Validation Example\n",
    "\n",
    "This notebook demonstrates how to use the Subject-Aware Model Validation Pipeline for **sepsis detection in ICU patients** using repeated measures data.\n",
    "\n",
    "## Clinical Context\n",
    "\n",
    "**Sepsis** is a life-threatening condition that requires early detection in ICU patients. Key challenges:\n",
    "\n",
    "- **Time-critical**: Early detection (within 6 hours) significantly improves outcomes\n",
    "- **Repeated measures**: Patients have hourly vital signs and lab values during ICU stay\n",
    "- **Data leakage risk**: Standard CV can use later measurements to predict earlier sepsis onset\n",
    "- **Class imbalance**: Most ICU patients don't develop sepsis (~10-20% prevalence)\n",
    "\n",
    "## Why Subject-Aware Validation Matters\n",
    "\n",
    "In sepsis detection:\n",
    "- Each patient has 12-168 hourly measurements during ICU stay\n",
    "- Patients have individual baseline vital signs patterns\n",
    "- Standard CV can learn patient-specific patterns rather than generalizable sepsis indicators\n",
    "- **LOPOCV ensures models generalize to new patients, not just new time points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Sepsis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic sepsis detection data\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Generate test data for sepsis detection\n",
    "print(\"🏥 Generating synthetic ICU sepsis data...\")\n",
    "result = subprocess.run([\n",
    "    sys.executable, 'generate_sepsis_data.py',\n",
    "    '--output_dir', './sepsis_data/',\n",
    "    '--single_dataset', '10',\n",
    "    '--n_patients', '30'\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the generated sepsis data\n",
    "df = pd.read_pickle('./sepsis_data/filtered_df_10GBC.pkl')\n",
    "\n",
    "print(\"📊 Sepsis Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Patients: {df.index.str.split('_').str[0].nunique()}\")\n",
    "print(f\"Total measurements: {len(df)}\")\n",
    "print(f\"Sepsis prevalence: {(df['target'] == 1).mean():.1%}\")\n",
    "\n",
    "# Show feature columns\n",
    "clinical_features = [col for col in df.columns if col not in ['target', 'patient_id', 'age', 'gender', 'apache_ii_score', 'hour']]\n",
    "print(f\"\\n🩺 Clinical Features ({len(clinical_features)}):\")\n",
    "for i, feature in enumerate(clinical_features[:10]):\n",
    "    print(f\"  {i+1:2d}. {feature}\")\n",
    "if len(clinical_features) > 10:\n",
    "    print(f\"  ... and {len(clinical_features)-10} more\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patient-level patterns\n",
    "patient_stats = df.groupby(df.index.str.split('_').str[0]).agg({\n",
    "    'target': ['sum', 'mean', 'count'],\n",
    "    'heart_rate': 'mean',\n",
    "    'temperature': 'mean',\n",
    "    'white_blood_cells': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "patient_stats.columns = ['sepsis_hours', 'sepsis_rate', 'icu_stay_hours', 'avg_hr', 'avg_temp', 'avg_wbc']\n",
    "\n",
    "print(\"👥 Patient-Level Statistics:\")\n",
    "print(f\"Patients with sepsis: {(patient_stats['sepsis_hours'] > 0).sum()}/{len(patient_stats)}\")\n",
    "print(f\"Average ICU stay: {patient_stats['icu_stay_hours'].mean():.1f} hours\")\n",
    "print(f\"Average sepsis duration: {patient_stats[patient_stats['sepsis_hours'] > 0]['sepsis_hours'].mean():.1f} hours\")\n",
    "\n",
    "patient_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sepsis patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Sepsis prevalence over ICU stay\n",
    "hourly_sepsis = df.groupby('hour')['target'].mean()\n",
    "axes[0,0].plot(hourly_sepsis.index, hourly_sepsis.values * 100)\n",
    "axes[0,0].set_title('Sepsis Prevalence by ICU Hour')\n",
    "axes[0,0].set_xlabel('ICU Hour')\n",
    "axes[0,0].set_ylabel('Sepsis Prevalence (%)')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Vital signs distribution by sepsis status\n",
    "vital_signs = ['heart_rate', 'temperature', 'systolic_bp', 'respiratory_rate']\n",
    "df_sample = df.sample(1000) if len(df) > 1000 else df  # Sample for faster plotting\n",
    "\n",
    "for i, vital in enumerate(vital_signs):\n",
    "    row, col = (i//2), (i%2)\n",
    "    if i == 0: continue  # Skip first subplot (already used)\n",
    "    \n",
    "    # Adjust indices for remaining subplots\n",
    "    if i == 1:\n",
    "        ax = axes[0,1]\n",
    "    elif i == 2:\n",
    "        ax = axes[1,0]\n",
    "    else:\n",
    "        ax = axes[1,1]\n",
    "    \n",
    "    sns.boxplot(data=df_sample, x='target', y=vital, ax=ax)\n",
    "    ax.set_title(f'{vital.replace(\"_\", \" \").title()} by Sepsis Status')\n",
    "    ax.set_xlabel('Sepsis Status (0=No, 1=Yes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show the data leakage potential\n",
    "print(\"\\n⚠️  Potential Data Leakage Analysis:\")\n",
    "print(\"Patient-specific baseline differences (could cause leakage):\")\n",
    "patient_baselines = df.groupby(df.index.str.split('_').str[0])[['heart_rate', 'systolic_bp', 'temperature']].mean()\n",
    "print(f\"Heart rate range: {patient_baselines['heart_rate'].min():.1f} - {patient_baselines['heart_rate'].max():.1f} bpm\")\n",
    "print(f\"Blood pressure range: {patient_baselines['systolic_bp'].min():.1f} - {patient_baselines['systolic_bp'].max():.1f} mmHg\")\n",
    "print(f\"Temperature range: {patient_baselines['temperature'].min():.1f} - {patient_baselines['temperature'].max():.1f} °C\")\n",
    "print(\"\\n📝 These patient-specific patterns could be learned by standard CV,\")\n",
    "print(\"   leading to overly optimistic performance estimates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Subject-Aware Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start MLflow server (if not already running)\n",
    "import subprocess\n",
    "import time\n",
    "import requests\n",
    "\n",
    "def check_mlflow_server():\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:5000\", timeout=3)\n",
    "        return response.status_code == 200\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if not check_mlflow_server():\n",
    "    print(\"🚀 Starting MLflow server...\")\n",
    "    mlflow_process = subprocess.Popen(\n",
    "        [\"mlflow\", \"ui\", \"--host\", \"0.0.0.0\", \"--port\", \"5000\"],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    # Wait for server to start\n",
    "    for _ in range(20):\n",
    "        time.sleep(1)\n",
    "        if check_mlflow_server():\n",
    "            print(\"✅ MLflow server started successfully\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"❌ MLflow server failed to start\")\nelse:\n",
    "    print(\"✅ MLflow server already running\")\n",
    "\n",
    "print(\"\\n📊 Access MLflow UI at: http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the validation pipeline\n",
    "print(\"🏃 Running sepsis detection validation pipeline...\")\n",
    "print(\"This will compare:\")\n",
    "print(\"  • Standard 10-Fold CV (potential data leakage)\")\n",
    "print(\"  • Leave-One-Patient-Out CV (subject-aware)\")\n",
    "print(\"  • Group 3-Fold CV (balanced subject-aware)\")\n",
    "print(\"\\nExpected runtime: 5-15 minutes depending on your hardware\\n\")\n",
    "\n",
    "result = subprocess.run([\n",
    "    sys.executable, 'main.py', \n",
    "    '--config', 'config_sepsis.yaml'\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(\"📋 Pipeline Output:\")\n",
    "print(result.stdout)\n",
    "\n",
    "if result.stderr:\n",
    "    print(\"\\n❌ Errors:\")\n",
    "    print(result.stderr)\n",
    "    \n",
    "if result.returncode == 0:\n",
    "    print(\"\\n✅ Pipeline completed successfully!\")\n",
    "    print(\"📊 Check MLflow UI for detailed results: http://localhost:5000\")\n",
    "else:\n",
    "    print(f\"\\n❌ Pipeline failed with return code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Results and Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze results\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path('./sepsis_results/')\n",
    "\n",
    "# Find results files\n",
    "result_files = list(results_dir.glob('*.csv'))\n",
    "print(f\"📊 Found {len(result_files)} result files:\")\n",
    "for file in result_files:\n",
    "    print(f\"  • {file.name}\")\n",
    "\n",
    "# Load combined performance results\n",
    "perf_file = results_dir / 'combined_performance_idx10.csv'\n",
    "if perf_file.exists():\n",
    "    results_df = pd.read_csv(perf_file)\n",
    "    print(f\"\\n📈 Performance Results Shape: {results_df.shape}\")\n",
    "    print(\"\\nColumns:\", list(results_df.columns)[:10], \"...\" if len(results_df.columns) > 10 else \"\")\nelse:\n",
    "    print(\"\\n⚠️  Combined performance file not found. Check pipeline execution.\")\n",
    "    # Try to find individual CV strategy files\n",
    "    cv_files = list(results_dir.glob('*/perf_*.csv'))\n",
    "    print(f\"Found {len(cv_files)} individual CV result files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data leakage by comparing CV strategies\n",
    "if 'results_df' in locals() and not results_df.empty:\n",
    "    # Extract key metrics for comparison\n",
    "    # Note: Column names may vary based on pipeline implementation\n",
    "    # This is a template - adjust column names based on actual output\n",
    "    \n",
    "    print(\"🔍 Data Leakage Analysis - Comparing CV Strategies:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Try to identify different CV strategies in results\n",
    "    # Look for patterns in column names or load separate files\n",
    "    cv_strategies = ['10Fold', 'LOPOCV', 'Group3Fold']\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for strategy in cv_strategies:\n",
    "        strategy_file = results_dir / strategy / f'perf_{strategy}_idx10.csv'\n",
    "        if strategy_file.exists():\n",
    "            strategy_df = pd.read_csv(strategy_file)\n",
    "            \n",
    "            # Extract performance metrics (adjust column names as needed)\n",
    "            # Common patterns: look for accuracy, F1, etc. in column names\n",
    "            accuracy_cols = [col for col in strategy_df.columns if 'accuracy' in col.lower()]\n",
    "            f1_cols = [col for col in strategy_df.columns if 'f1' in col.lower()]\n",
    "            \n",
    "            if accuracy_cols:\n",
    "                acc_values = strategy_df[accuracy_cols].mean().mean()\n",
    "                comparison_data.append({\n",
    "                    'CV_Strategy': strategy,\n",
    "                    'Avg_Accuracy': acc_values,\n",
    "                    'File_Found': True\n",
    "                })\n",
    "            else:\n",
    "                comparison_data.append({\n",
    "                    'CV_Strategy': strategy,\n",
    "                    'Avg_Accuracy': None,\n",
    "                    'File_Found': True\n",
    "                })\